{"componentChunkName":"component---templates-post-tsx-content-file-path-content-posts-tech-vibe-coding-2025-mdx","path":"/blog/tech/vibe-coding-2025/","result":{"data":{"mdx":{"body":"\n## Preface: I'm an AI naysayer\n\nI've been a software engineer for almost 7 years now. As someone who is self-taught, I'm open to\nunconventional experiences and methods when it comes to building something. I believe that how\nsomeone builds something is a reflection of their previous experiences and mistakes. When it comes\nto AI generated code, you would think that the experiences and mistakes of every piece of training\ndata would result in code generation that is sound and thoughtful. But that's just the thing: AI\ndoesn't think. These LLMs are just prediction models at their core. One could argue that the human\nbrain is just one large prediction model and I could agree with that, but the difference is that we\nhave so much more context than LLMs can support. We have _years_ of context.\n\nI also believe there are _consequences_ to using AI, whether for learning or productivity and this\nextends past just software engineering. Here are a few of those trade offs that we should be\nconsidering:\n\n1. Environmental impacts - we don't know how much of a toll the infrastructure to support model\n   training and model hosting is going to take on natural resources, but we can\n   [estimate at this point](https://apnews.com/article/ai-data-center-climate-impact-environment-c6218681ffdbad5bf427b47347fddcb9)\n   and the energy usage is very alarming. More and more companies are forcing AI on people, both\n   employees and products, which compounds these effects.\n2. Familiarity is built during the development process and is paramount to being able to design\n   other features, find bugs, and answer questions about what you've produced. The more code that's\n   generated, the less familiar you are with it.\n3. I believe we learn best by making mistakes. By using LLMs, mistakes are masked and \"solved\" by\n   the LLM. We lose all of those valuable learning opportunities.\n\nSo I don't use LLMs to write functional code. The cost is too great.\n\n## Vibe coding\n\nAt this point, we all know what vibe coding is. I like to stay on top of new technologies and from a\nprofessional perspective, I think it would be irresponsible to never try using an LLM to write\n_some_ code, so why not all of it for a tiny project? My partner is planning on getting her driving\nlicense soon (not because she's a teenager, to be clear) and so I wanted to help her study for the\nWashington state knowledge test which is required in addition to the driving test. The resources out\nthere to study are not great:\n\n- [Washington's own guide](https://dol.wa.gov/driver-licenses-and-permits/driver-training-and-testing/driver-guides)\n  is almost 200 page pdf\n- [Other sites](https://driving-tests.org/washington/) require payment and are just practice driving\n  tests\n\nOne good resource I found was\n[Defensive Driving School's \"Numbers to Know\" PDF](https://driving-school.com/wp-content/uploads/2020/01/Numbers-to-Know.pdf).\n\nWhat I want is a site for studying with flashcards and then randomly generated practice tests.\nSounds simple enough, the perfect opportunity to give vibe coding a shot!\n\n**Here are my requirements:**\n\n- Web application\n- Flashcards that can be shuffled with questions and answers for the WA DOL knowledge test\n- 40 question practice test, multiple choice, shuffled questions\n\n### Set up\n\nI don't like subscriptions. Luckily, most AI providers offer API keys which use credits that are one\ntime purchases. There are also two main methods of vibe coding that I'm aware of:\n\n1. In an IDE like [Cursor](https://cursor.com/) or [Windsurf](https://windsurf.com/)\n2. A terminal agent like [Claude code](https://claudecode.io/)\n\nThere are some browser based agents like [v0](https://v0.app/), but I would like a bit of a hand in\nsome of the source code. As for the type of application, a simple [vite](https://vite.dev/)\n[React](https://react.dev/) app with [Typescript](https://www.typescriptlang.org/) is what I want.\n\nThe agent I decided to go with is [OpenCode](https://opencode.ai/) which is a terminal based agent\nthat I can use an API key with, perfect! I opted to use\n[Claude Sonnet 4.5](https://www.anthropic.com/news/claude-sonnet-4-5) for this project as I've heard\nmore good things about Claude than other models.\n\n**So here's the summary of the setup:**\n\n- Vite React/TS app\n- PDF driver's guide from\n  [WA DOL site](https://dol.wa.gov/driver-licenses-and-permits/driver-training-and-testing/driver-guides)\n- [Numbers to know from Defensive Driving School](https://driving-school.com/wp-content/uploads/2020/01/Numbers-to-Know.pdf)\n- Opencode agent\n- Claude Sonnet 4.5 for model\n\nFor fun, I planned on not looking at **any code** that the agent generates until the project is\ncomplete. Project structure is also up to the agent.\n\n### Initial prompt\n\nHere was my initial prompt:\n\n> I want to create a flashcard app for the washington state department of licensing knowledge test.\n> There are two pdfs in this repo, one is the numbers to know, the second is the resource from the\n> state containing all rules of the road. I want the bank of questions and answers in json format\n> for ease of auditing.\n\nMy OpenCode Claude agent started off attempting to read the PDF and opted for writing a Python\nscript to read the PDF since I have a version of Python installed.\n\n![Vibe coding looking for pdf extraction tool](images/vibe-coding_pdftotext.png)\n\nThis did not work as the library that the agent wanted to use was not installed. The agent then\nopted to write a bash script to read the PDF manually which also didn't work. Not a great start. The\nagent then attempted _another_ Python script and failed as expected. As a last resort, the agent\nasked me to manually input the data as seen above. I ended up installing `pdftotext` myself and\nletting the agent know that I had installed it. With the expected output, the agent created the\nquestion bank successfully from the \"Numbers to Know\" PDF.\n\nI later asked to pull advanced questions from the full guide, but the PDF was too big. Luckily, the\nWA DOL site had an html text only version that was simplified. The agent was able to parse out a\ntotal of 54 questions and I ended up just using this instead of the \"Numbers to Know\" questions as\nthere was some significant overlap.\n\n### UI\n\nNext step was to get some flashcard UI going and I wanted the agent to use\n[shadcn](https://ui.shadcn.com/) in conjunction with [tailwindcss](https://tailwindcss.com/), modern\nweb framework tools. I purposefully did not include these in my project setup to see how the agent\nwould install them. This went mostly smooth. The agent had a hard time with the initialization of\ntailwind with my package manager `pnpm` and ended up creating the config manually:\n\n![Vibe coding installing Tailwindcss](images/vibe-coding_tailwind-install.png)\n\nLater, I learned that this manual Tailwind config was incorrect for the version we had installed and\nthe config had to be updated again:\n\n![Vibe coding updating Tailwind config](images/vibe-coding_update-tailwind.png)\n\nAnother interesting, uh, \"choice\" that the agent made was to just manually create the shadcn\ncomponents rather than just follow the typical component installation. For those unfamiliar with\nshadcn, components are typically installed via their\n[CLI tool](https://ui.shadcn.com/docs/installation/vite) which does just clone components into your\nrepository. Did the agent create the correct components? Not sure yet. I'll look at the code at the\nend to compare.\n\n![Vibe coding installing shadcn](images/vibe-coding_shadcn.png)\n\nFrom here on out, development consisted of:\n\n- Some minor back and forth, tuning the UI for better UX\n- Adding animations\n- Fixing bugs (typically one to three prompts)\n- The agent's overconfident \"fixed!\" responses\n\n### Practice test\n\nThe last feature to vibe in was the practice test feature. This takes the flashcards and turns them\ninto multiple choice questions with reasonable, similar answers compared to the correct answer.\nHere, the agent got the practice test UI up and going with ease. The content however, was a bit of a\nstruggle. For some reason, the agent decided to dynamically generate question answers for every\ntest.\n\n![Vibe coding generate question answers](images/vibe-coding_plan.png)\n\nThis had some interesting results:\n\n<div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 px-8 md:[&_img]:my-0 md:[&_.gatsby-resp-image-wrapper]:!px-0\">\n  ![Vibe coding bad answers1](images/vibe-coding_bad-answers1.png) ![Vibe coding bad\n  answers2](images/vibe-coding_bad-answers2.png)\n</div>\n\nI prompted for iteration on this, and the agent ended up tweaking its algorithm and that resulted in\nan infinite loop. I ended up having to prompt it to generate the similar answers on its own and\nstore those in the JSON question bank. That worked much better.\n\n<Callout>\n\nOne thing you might have noticed is that I haven't shared much of what the UI _looks_ like or the\niterations that it's been through. There's one thing that these agents could do better which is\nversion control. Do I want these agents to be able to access `git`? Not really, but they already\nhave access (with permission) to run commands in a terminal so why not `git`? If I could say\n\"develop on this one branch and commit frequently\", I could be able to go back and look at how the\nUI has progressed. Part of that is on me for not taking screenshots though so I won't count this\nagainst the agent.\n\n</Callout>\n\n### Deployment\n\nSo far we have had the agent do the \"backend\" and the frontend, so let's have it do the deployment\nas well. I want to be able to deploy this to Github pages and deploy to my local network with a\nDocker container. I understand this is probably out of the realm that a normal vibe-coder would\nwant, but I don't want to pay for a hosting solution. The agent claims to have built out the two\ndeployment options that I requested so let's test them out.\n\n![Vibe coding deployment](images/vibe-coding_deployment.png)\n\nStarting with the Docker container, the Dockerfile did not result in a successful local deployment.\nPasting in the error message, the agent believed that the error has to do with routing via the base\npath. Look at that! The Docker container now works. Hosting this application locally is another\nstory. It has more to do with my local network setup rather than the application, so I'll skip that\nhere now that I have a working container.\n\nAs for Github pages, that deployment is next. I committed the changes to see what happens.\n\n![Vibe coding github deployment failure](images/vibe-coding_github-failure.png)\n\nSeems like a relatively simple error. I pasted the results into opencode and commit the edits. Drum\nroll please... success! The app was built and deployed. We can finally call this project \"done\"\nsince it's now live.\n\n<Callout type=\"tip\">\n  See the application [here](https://balake.github.io/wadol-knowledge-test/)! Note that any changes\n  made since this post will be only to correct questions or facts presented as I doubt the agent\n  parsed things 100% factually.\n</Callout>\n\nHere are some screenshots of the application also as proof.\n\n![Vibe coding flashcard](images/vibe-coding_flashcard.png)\n\n![Vibe coding question](images/vibe-coding_question.png)\n\nBonus: I took the test. Maybe I should study a bit 🫠. Worth noting here passing is 80%, not 70%.\nNot sure where the agent got that, but I will be going through and verifying all the questions and\nanswers before handing this off to my partner.\n\n![Vibe coding score](images/vibe-coding_score.png)\n\n## The code\n\nLet's look at the code that the agent generated with Claude Sonnet 4.5. I haven't looked at it yet,\nso I'm quite curious. Feel free to browse the code yourself\n[here](https://github.com/Balake/wadol-knowledge-test).\n\n### Structure\n\nRight off the bat, structure for this project appears to be mostly in order. There are some\ninteresting artifacts including the `App.css` file from the vite setup that is no longer used. It's\ngenerally good that these agents don't clean up files as that reduces the chance of removing files\nthat are important.\n\nOne thing that I would have done differently structure-wise is setup a directory for component\ncontainers rather than just \"components\", but that's a bit pedantic. I also would have split some of\nthe app logic out into a `React.context` for some separation of concerns. Structure is somewhat\nsubjective and this app is not very complicated, so I give agent generated structure: 👍\n\n![Vibe coding structure](images/vibe-coding_structure.png)\n\nI also never specified installing `eslint`, so that's an interesting addition, but overall, a net\npositive here. I know the agent used `eslint` to verify some of its work.\n\n### UI\n\nI'll preface this next section with: I'm not a frontend engineer. I do everything, but frontend is\nwhere I feel like I know the least, especially with modern web frameworks.\n\nThe first question I have is: did the agent get the shadcn components correct? Rather than using the\ninstall tool from shadcn, the agent just generated the components itself. Here is the generated\n`Badge` component:\n\n```typescript\nimport * as React from \"react\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\nimport { cn } from \"@/lib/utils.ts\"\n\nconst badgeVariants = cva(\n  \"inline-flex items-center rounded-md border border-slate-200 px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-slate-950 focus:ring-offset-2\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"border-transparent bg-slate-900 text-slate-50 shadow hover:bg-slate-900/80\",\n        secondary:\n          \"border-transparent bg-slate-100 text-slate-900 hover:bg-slate-100/80\",\n        outline: \"text-slate-950\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n)\n\nexport interface BadgeProps\n  extends React.HTMLAttributes<HTMLDivElement>,\n    VariantProps<typeof badgeVariants> {}\n\nfunction Badge({ className, variant, ...props }: BadgeProps) {\n  return (\n    <div className={cn(badgeVariants({ variant }), className)} {...props} />\n  )\n}\n\nexport { Badge }\n```\n\nAnd here is the `Badge` from shadcn:\n\n```typescript\nimport * as React from \"react\"\nimport { Slot } from \"@radix-ui/react-slot\"\nimport { cva, type VariantProps } from \"class-variance-authority\"\n\nimport { cn } from \"@/lib/utils\"\n\nconst badgeVariants = cva(\n  \"inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90\",\n        secondary:\n          \"border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90\",\n        destructive:\n          \"border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60\",\n        outline:\n          \"text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n)\n\nfunction Badge({\n  className,\n  variant,\n  asChild = false,\n  ...props\n}: React.ComponentProps<\"span\"> &\n  VariantProps<typeof badgeVariants> & { asChild?: boolean }) {\n  const Comp = asChild ? Slot : \"span\"\n\n  return (\n    <Comp\n      data-slot=\"badge\"\n      className={cn(badgeVariants({ variant }), className)}\n      {...props}\n    />\n  )\n}\n\nexport { Badge, badgeVariants }\n```\n\nAlright so the component that the agent generated is quite a bit different than the shadcn version.\nHere are some of the differences that I notice on the agent version:\n\n- The `destructive` variant is missing from the `Badge` variants\n- The default variant styles are different:\n  - Manually specifies colors rather than use Tailwind variables like `primary` or `secondary`\n  - Missing the `transition` properties\n  - Different padding values\n  - Doesn't support anchor (`<a/>`) tags\n- Support for `asChild` is missing which is quite useful.\n- Exporting the `badgeVariants` is missing as well which is useful for types\n\n<Callout type=\"tip\">\n  Here's some [additional\n  reading](https://medium.com/@bryanmylee/aschild-in-react-svelte-vue-and-solid-for-render-delegation-645c73650ced)\n  on the `asChild` pattern and why it's important.\n</Callout>\n\nThis is just the first component. I suspect that the others will be similar. I will note that shadcn\ncomponents can be customized, but I asked the agent for just default shadcn components.\n\nThe manual color specifications that the agent did in these components got me curious... Maybe there\nisn't a Tailwind theme? And there's not. Whose fault would that be? Every frontend project that I've\nworked on has used a Tailwind theme. The theme is a\n[core concept](https://tailwindcss.com/docs/theme) of Tailwind. This is a clear miss by the agent.\n\n### Data\n\nLet's take a look at the underlying data structure powering this app. There's not a ton here to look\nat, but still worth taking a peek.\n\n```json\n{\n  \"title\": \"Washington State Driver's License - Advanced Knowledge\",\n  \"categories\": [\n    {\n      \"id\": \"stopping-distances\",\n      \"name\": \"Stopping & Following Distances\",\n      \"questions\": [\n        {\n          \"id\": \"stop-1\",\n          \"question\": \"How long does it take a loaded truck with properly adjusted brakes, traveling at 55 mph, to come to a complete stop?\",\n          \"answer\": \"450\",\n          \"unit\": \"feet\",\n          \"wrongAnswers\": [\"300 feet\", \"400 feet\", \"500 feet\"]\n        },\n        {\n          \"id\": \"stop-2\",\n          \"question\": \"At what distance should you usually be able to stop within the glow of your headlights?\",\n          \"answer\": \"400\",\n          \"unit\": \"feet\",\n          \"wrongAnswers\": [\"300 feet\", \"500 feet\", \"600 feet\"]\n        },\n        {\n          \"id\": \"stop-3\",\n          \"question\": \"How far ahead should you pick out a marker (like a road sign) when counting seconds for following distance?\",\n          \"answer\": \"15\",\n          \"unit\": \"seconds\",\n          \"wrongAnswers\": [\"10 seconds\", \"12 seconds\", \"20 seconds\"]\n        },\n        {\n          \"id\": \"stop-4\",\n          \"question\": \"What is the minimum distance you should stop from the nearest rail of a railroad crossing?\",\n          \"answer\": \"15\",\n          \"unit\": \"feet\",\n          \"wrongAnswers\": [\"10 feet\", \"20 feet\", \"25 feet\"]\n        },\n        {\n          \"id\": \"stop-5\",\n          \"question\": \"What is the maximum distance you should stop from the nearest rail of a railroad crossing?\",\n          \"answer\": \"50\",\n          \"unit\": \"feet\",\n          \"wrongAnswers\": [\"40 feet\", \"60 feet\", \"75 feet\"]\n        }\n      ]\n    },\n    ...\n  ]\n}\n```\n\nOverall, not bad. Is this how I would have done it? No, I don't think so, but this gets the job done\nand it's easy enough to add new questions or edit them. I do think that specifically the `unit`\nproperty is interesting as it's not used outside of formatting the answer. Why not just have that be\npart of the answer? I'm not sure what the point of it is.\n\n## Conclusion\n\nThe agent definitely generated some code. No attempt was made at cleanup. What I asked for vs what I\ngot was never the first attempt, but that's true for any engineering project. I'm disappointed in\nthe agent not following shadcn or Tailwind standards. I've heard others say these agents operate\nintellectually at a junior level, and I think that's a fair comparison.\n\nOne final aspect of this process that is worth considering is _time_ and _cost_. These agents are\nsupposed to save us time right? Well I'm not convinced that any time was saved. I think this is\nsomething that I could have done in a couple hours. I still have to go through and verify all the\nquestions and answers before sharing with my partner.\n\nThe following images are the _cost_ associated with building this app, taken from claude console:\n\n<div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 px-8 md:[&_img]:my-0 md:[&_.gatsby-resp-image-wrapper]:!px-0\">\n  ![Vibe coding tokens](images/vibe-coding_tokens.png) ![Vibe coding\n  cost](images/vibe-coding_cost.png)\n</div>\n\nCould I have prompted better? Absolutely. Did I learn anything while doing this? I learned that I\nwon't be vibe coding ever again, reinforcing my AI skepticism. I feel like I actively contributed to\nthe climate crisis. The hype is not real. Maybe it will be in the future, but today is not that day.\n\n\\- Balake, not a vibe coder\n","fields":{"timeToRead":{"minutes":14.88,"text":"15 min read","time":892800,"words":2976}},"frontmatter":{"title":"First time vibe coding 🤔","description":"As an AI naysayer, I try vibe coding for the first time. Does AI gain any brownie points?","date":"10-11-2025"}}},"pageContext":{"id":"7c9bfc84-425b-5361-81f6-5a9e7a8f04e4","frontmatter":{"title":"First time vibe coding 🤔","date":"10-11-2025","description":"As an AI naysayer, I try vibe coding for the first time. Does AI gain any brownie points?"}}},"staticQueryHashes":[],"slicesMap":{}}